# 'cuu-illegal-waste'

This code was developed by JNCC under the Copernicus User Uptake Work Package 6 project focussing on monitoring illegal waste using Sentinel-1 imagery. This project is joint-funded by Scottish Government through the JNCC Simple Analysis Ready Data Service Project. 

## Setup venv

```
cd orchestration
python -m venv .venv
source .venv/bin/activate
```

## Running Luigi script

Create a `illegal-waste-orchestration-luigi.cfg` file using the template and run it like so:

```
LUIGI_CONFIG_PATH=orchestration/illegal-waste-orchestration-luigi.cfg PYTHONPATH='.' luigi --module orchestration SubmitJobs --outputSRS=27700 --testProcessing --local-scheduler
```

Use the `--testProcessing` flag to test locally or it will try and actually submit the jobs.

The inputs can be dummy files, e.g. the following:

```
S1B_IW_SLC__1SDV_20201216T175827_20201216T175854_024731_02F107_7A4B.zip
S1B_IW_SLC__1SDV_20201204T175828_20201204T175855_024556_02EB54_47B6.zip
S1B_IW_SLC__1SDV_20201122T175828_20201122T175855_024381_02E5CA_0DC7.zip
S1B_IW_SLC__1SDV_20201110T175829_20201110T175856_024206_02E040_D8A8.zip
S1B_IW_SLC__1SDV_20201228T175827_20201228T175854_024906_02F6B2_FD92.zip
```

## Create a processing environment

It is best practice to create a processing environment for each processing job you wish to run (i.e. a single scene over time in this case), once you have downloaded your files using the downloader and have a list of files that you want to process, it is easiest to just have single folder of all inputs for a run with no other files in there, but if you have a mixed folder you can create a new input folder using symlinks or moving files into a single directory.

In the case that files may be used by multiple processing environments we suggest you create a folder and symlink all files that you need into that folder this can be done using `ln -s destPath srcPath` or using `cp -s srcFile destPath` to create the symlinks.

Once you have a single folder with all of the input S1 zip files that you want to process as pairs we can start to create the rest of the processing environment, we will refer to this folder as the `input` folder from this point on when refering to the orchestration tool.

### Create internal directories

For each environment you will need to create a `basket`, `state`, `static`, `working` and `output` directory as well as the initially created `input` directory above.

In your workspace area create a folder to store these for this particular processing environment;

  - `basket` is the folder which will contain symlinks for each pair discovered from the `input` folder, these pairs are fed to the processing container via sbatch
  - `state` contains the state for this orchestration 
  - `static` is a folder for holding static config files, it is unused in this particular workflow
  - `working` is a folder which will contain the generated sbatch files for submission to the queues and the state directories for each container
  - `output` is a folder which will contain the final outputs generated by the containers when they are run

### Create a Luigi config for an environment

To configure your environment you will need to take a copy of the `illegal-waste-orchestration-luigi.cfg.template` and modify it to match your current environment i.e.

```
[SubmitJobs]
stateLocation=/[ENV]/state
workingLocation=/[ENV]/working
outputLocation=/[ENV]/output
staticLocation=/[ENV]/static
containerPath=/containers/cuu-illegal-waste-[VERSION].sif
templateFile=/code/cuu-illegal-waste/orchestration/templates/process_illegal_waste_job_template.sbatch
```

In this case `[ENV]` is a working directory, `/containers` is the path to the containers directory where singularity containers are kept and `/code/cuu-illegal-waste` is a checked out version of this repo.

### Running a processing job for an environment

To run the processing orchestration worklow you can run LUIGI as follows;

`LUIGI_CONFIG_PATH='/[ENV]/illegal-waste-orchestration-luigi.cfg' PYTHONPATH='/code/cuu-illegal-waste' luigi --module orchestration SubmitJobs --local-scheduler --basketLocation=/[ENV]/basket --inputLocation=/[ENV]/input --outputSRS=27700`

Where the `/[ENV]/input` folder points to your working input folder containing either symlinks or the raw files that you want to process (note this workflow considers all files in the directory to be part of the pair processing, so that is the only S1 zip files that will pair up).
